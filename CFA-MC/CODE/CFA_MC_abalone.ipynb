{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pPyIz9jP2D9",
        "outputId": "232cdafb-2ba8-4962-f0b3-7378a66a8982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CFA-CFA_MC')"
      ],
      "metadata": {
        "id": "Y_F4tfQDRNBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/CFA-CFA_MC/abalone.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ovhn5_uLRRD5",
        "outputId": "2b5d46b2-f2c3-4898-cc94-09d101d3e038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
              "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
              "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
              "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
              "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
              "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
              "...   ..     ...       ...     ...           ...             ...   \n",
              "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
              "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
              "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
              "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
              "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
              "\n",
              "      Viscera weight  Shell weight  Rings  \n",
              "0             0.1010        0.1500     15  \n",
              "1             0.0485        0.0700      7  \n",
              "2             0.1415        0.2100      9  \n",
              "3             0.1140        0.1550     10  \n",
              "4             0.0395        0.0550      7  \n",
              "...              ...           ...    ...  \n",
              "4172          0.2390        0.2490     11  \n",
              "4173          0.2145        0.2605     10  \n",
              "4174          0.2875        0.3080      9  \n",
              "4175          0.2610        0.2960     10  \n",
              "4176          0.3765        0.4950     12  \n",
              "\n",
              "[4177 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f1b2bb9-7dd0-48dd-a756-f35dd722cb53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.5140</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>F</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>M</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.2605</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>M</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>F</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.150</td>\n",
              "      <td>1.0945</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>M</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.9485</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.3765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4177 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f1b2bb9-7dd0-48dd-a756-f35dd722cb53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f1b2bb9-7dd0-48dd-a756-f35dd722cb53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f1b2bb9-7dd0-48dd-a756-f35dd722cb53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-723be6e6-86e9-402b-9456-803e7b5d1ecf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-723be6e6-86e9-402b-9456-803e7b5d1ecf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-723be6e6-86e9-402b-9456-803e7b5d1ecf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f64cd772-121a-4746-83f5-130879fbae2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f64cd772-121a-4746-83f5-130879fbae2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4177,\n  \"fields\": [\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"M\",\n          \"F\",\n          \"I\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12009291256479956,\n        \"min\": 0.075,\n        \"max\": 0.815,\n        \"num_unique_values\": 134,\n        \"samples\": [\n          0.815,\n          0.65,\n          0.29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09923986613365945,\n        \"min\": 0.055,\n        \"max\": 0.65,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          0.09,\n          0.35,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041827056607257274,\n        \"min\": 0.0,\n        \"max\": 1.13,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          0.235,\n          0.035,\n          0.015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Whole weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4903890182309977,\n        \"min\": 0.002,\n        \"max\": 2.8255,\n        \"num_unique_values\": 2429,\n        \"samples\": [\n          1.2825,\n          1.09,\n          0.131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shucked weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22196294903322014,\n        \"min\": 0.001,\n        \"max\": 1.488,\n        \"num_unique_values\": 1515,\n        \"samples\": [\n          0.2105,\n          0.0645,\n          0.476\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Viscera weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10961425025968446,\n        \"min\": 0.0005,\n        \"max\": 0.76,\n        \"num_unique_values\": 880,\n        \"samples\": [\n          0.0645,\n          0.0095,\n          0.1115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shell weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1392026695223861,\n        \"min\": 0.0015,\n        \"max\": 1.005,\n        \"num_unique_values\": 926,\n        \"samples\": [\n          0.3745,\n          0.2825,\n          0.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          11,\n          27,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe data: name\n",
        "\n",
        "data['Rings'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "Wwe-idOaTLdT",
        "outputId": "3c167a58-de31-438a-ab69-f4fcab049573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rings\n",
              "9     689\n",
              "10    634\n",
              "8     568\n",
              "11    487\n",
              "7     391\n",
              "12    267\n",
              "6     259\n",
              "13    203\n",
              "14    126\n",
              "5     115\n",
              "15    103\n",
              "16     67\n",
              "17     58\n",
              "4      57\n",
              "18     42\n",
              "19     32\n",
              "20     26\n",
              "3      15\n",
              "21     14\n",
              "23      9\n",
              "22      6\n",
              "27      2\n",
              "24      2\n",
              "1       1\n",
              "26      1\n",
              "29      1\n",
              "2       1\n",
              "25      1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rings</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "df = data.copy()\n",
        "\n",
        "# Encode categorical feature 'Sex'\n",
        "le = LabelEncoder()\n",
        "df['Sex'] = le.fit_transform(df['Sex'])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['Rings']).values\n",
        "y = df['Rings'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"\\n--- Random Forest Classifier ---\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# k-Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors as needed\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"\\n--- k-Nearest Neighbors Classifier ---\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Multilayer Perceptron Classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)  # Adjust parameters as needed\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "print(\"\\n--- Multilayer Perceptron Classifier ---\")\n",
        "print(classification_report(y_test, y_pred_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUZ1CasUihiN",
        "outputId": "91ddfb82-e16d-40ce-9054-bec40c597891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest Classifier ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.25      0.33      0.29         3\n",
            "           4       0.29      0.38      0.33        13\n",
            "           5       0.50      0.44      0.47        32\n",
            "           6       0.35      0.31      0.33        48\n",
            "           7       0.28      0.24      0.26        84\n",
            "           8       0.28      0.37      0.32        99\n",
            "           9       0.23      0.27      0.25       142\n",
            "          10       0.25      0.26      0.25       139\n",
            "          11       0.24      0.32      0.28        93\n",
            "          12       0.17      0.14      0.15        51\n",
            "          13       0.09      0.10      0.09        31\n",
            "          14       0.22      0.08      0.11        26\n",
            "          15       0.00      0.00      0.00        21\n",
            "          16       0.17      0.08      0.11        13\n",
            "          17       0.25      0.12      0.17         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.25       836\n",
            "   macro avg       0.17      0.16      0.16       836\n",
            "weighted avg       0.24      0.25      0.24       836\n",
            "\n",
            "\n",
            "--- k-Nearest Neighbors Classifier ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.22      0.31      0.26        13\n",
            "           5       0.27      0.22      0.24        32\n",
            "           6       0.32      0.38      0.35        48\n",
            "           7       0.29      0.31      0.30        84\n",
            "           8       0.25      0.39      0.31        99\n",
            "           9       0.25      0.31      0.28       142\n",
            "          10       0.21      0.19      0.20       139\n",
            "          11       0.22      0.19      0.21        93\n",
            "          12       0.05      0.04      0.04        51\n",
            "          13       0.08      0.06      0.07        31\n",
            "          14       0.22      0.08      0.11        26\n",
            "          15       0.60      0.14      0.23        21\n",
            "          16       0.20      0.08      0.11        13\n",
            "          17       0.00      0.00      0.00         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.23       836\n",
            "   macro avg       0.15      0.13      0.13       836\n",
            "weighted avg       0.22      0.23      0.22       836\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Multilayer Perceptron Classifier ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.38      0.77      0.51        13\n",
            "           5       0.43      0.19      0.26        32\n",
            "           6       0.37      0.40      0.38        48\n",
            "           7       0.40      0.42      0.41        84\n",
            "           8       0.38      0.43      0.41        99\n",
            "           9       0.33      0.51      0.40       142\n",
            "          10       0.23      0.27      0.25       139\n",
            "          11       0.30      0.28      0.29        93\n",
            "          12       0.00      0.00      0.00        51\n",
            "          13       0.09      0.16      0.12        31\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.00      0.00      0.00        21\n",
            "          16       0.00      0.00      0.00        13\n",
            "          17       0.00      0.00      0.00         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.31       836\n",
            "   macro avg       0.14      0.16      0.14       836\n",
            "weighted avg       0.26      0.31      0.27       836\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Váº½ Ä‘á»“ thá»‹ phÃ¢n phá»‘i cá»§a cá»™t 'Rings' cho dá»¯ liá»‡u gá»‘c\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Rings', data=data)\n",
        "plt.title('Distribution of the Rings column for the original data')\n",
        "plt.xlabel('Rings')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "_w3NF-AbbKp-",
        "outputId": "fd20add0-370a-4f7d-d27a-2e4bda9ef475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e99Bc8-4kUdq",
        "outputId": "279b4e2f-0cd0-48e2-a755-9b0a247f4671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from cfa import CFA\n",
        "\n",
        "# Encode categorical feature 'Sex'\n",
        "le = LabelEncoder()\n",
        "data['Sex'] = le.fit_transform(data['Sex'])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['Rings']).values\n",
        "y = data['Rings'].values\n",
        "\n",
        "# Identify minority classes in 'Rings'\n",
        "unique_classes, counts = np.unique(y, return_counts=True)\n",
        "minority_classes = unique_classes[counts < 100]\n",
        "\n",
        "# Apply CFA to balance minority classes in 'Rings'\n",
        "synthetic_instances = []\n",
        "synthetic_labels = []\n",
        "for minority_class in minority_classes:\n",
        "    print(f\"Balancing class: {minority_class}\")\n",
        "\n",
        "    # Create a binary target variable for the current minority class\n",
        "    y_binary = np.where(y == minority_class, 1, 0)\n",
        "\n",
        "    # Apply CFA\n",
        "    cfa = CFA(fd=2, tol=0.1)\n",
        "    X_resampled, y_resampled = cfa.run_cfa(X, y_binary)\n",
        "\n",
        "    # Extract synthetic instances for the current minority class\n",
        "    synthetic_indices = np.where(y_resampled[len(y):] == 1)[0]\n",
        "    synthetic_instances.extend(X_resampled[len(y):][synthetic_indices])\n",
        "    synthetic_labels.extend([minority_class] * len(synthetic_indices))\n",
        "\n",
        "# Combine original data with synthetic instances\n",
        "X_balanced = np.concatenate((X, synthetic_instances))\n",
        "y_balanced = np.concatenate((y, synthetic_labels))\n",
        "\n",
        "# Split the balanced data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_balanced, y_balanced, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# Train and evaluate classifiers\n",
        "# ----------------------------------\n",
        "\n",
        "# 1. Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# 2. k-Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# 3. Multilayer Perceptron Classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# ----------------------------------\n",
        "# Print evaluation results\n",
        "# ----------------------------------\n",
        "\n",
        "def evaluate_classifier(y_test, y_pred, classifier_name):\n",
        "    print(f\"\\n--- Evaluation for {classifier_name} ---\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "evaluate_classifier(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_classifier(y_test, y_pred_knn, \"k-Nearest Neighbors\")\n",
        "evaluate_classifier(y_test, y_pred_mlp, \"Multilayer Perceptron\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M935_UrnHDN",
        "outputId": "61c61cef-c976-45fd-945a-694dcdc07616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balancing class: 1\n",
            "Balancing class: 2\n",
            "Balancing class: 3\n",
            "Balancing class: 4\n",
            "Balancing class: 16\n",
            "Balancing class: 17\n",
            "Balancing class: 18\n",
            "Balancing class: 19\n",
            "Balancing class: 20\n",
            "Balancing class: 21\n",
            "Balancing class: 22\n",
            "Balancing class: 23\n",
            "Balancing class: 24\n",
            "Balancing class: 25\n",
            "Balancing class: 26\n",
            "Balancing class: 27\n",
            "Balancing class: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation for Random Forest ---\n",
            "Confusion Matrix:\n",
            " [[640  34   4  12   0   0   0   0   0   0   0   1   0   0   0  12   9   6\n",
            "    6  14  11  18  22  14   2   0  17   5]\n",
            " [ 53 100 275 218   4   0   8   3  12  13   9   2   3   5   1  17  20   9\n",
            "   15  10  14   6  14   8   1   2   1   4]\n",
            " [  9 201  91 343   3   4   5   5  13  12   9   3   3   3   1  20   7  10\n",
            "   32  11   4   4  18   8   4   8   1  13]\n",
            " [  5 200 251  45   2  12  22  23  43  33  24  16  13   9   6  14   9   4\n",
            "   15   6   6   3  20   2   0   1   3   1]\n",
            " [  0  11   3   4   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  15   8  18   2   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   1   0   2   0   0   0   0   0]\n",
            " [  1  22  13  39   0   0   0   1   0   0   0   0   0   0   0   1   3   1\n",
            "    0   0   0   0   2   0   0   0   0   0]\n",
            " [  1  31  27  47   0   0   0   0   0   0   0   0   0   0   0   1   3   1\n",
            "    0   0   0   1   4   0   0   0   0   2]\n",
            " [  1  25  27  68   0   0   0   0   0   1   0   0   0   0   0   0   3   2\n",
            "    0   3   1   0   1   0   0   0   0   2]\n",
            " [  1  24  28  57   0   0   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    2   1   0   1   5   1   0   0   0   0]\n",
            " [  1  22  23  37   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   2   0   0   0   1   2]\n",
            " [  0  12  19  16   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   1   1   0   1   0   0]\n",
            " [  1  11   8  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   1   0   1   3   0   0   0   0]\n",
            " [  0   6   3   6   0   0   0   0   0   0   0   0   0   0   0   1   3   0\n",
            "    0   0   0   0   0   1   0   0   0   0]\n",
            " [  0   6   3  12   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
            "    0   0   1   0   0   1   0   0   0   0]\n",
            " [ 22  42  35  27   0   0   0   2   2   0   1   0   1   0   0 389  40  28\n",
            "   28  40  22  26  14  24  13  16  14  28]\n",
            " [ 21  39  25  46   0   0   0   3   4   7   3   2   0   1   0  20 321  50\n",
            "   41  32  38  24  18  25  31  38   9  33]\n",
            " [ 19  23  25  20   0   0   0   0   0   3   0   1   0   1   0  27  58 378\n",
            "   23  23  83  20  26  21  15  39  11  29]\n",
            " [ 30  43  61  20   0   0   0   0   0   1   1   0   0   0   0  27  37  18\n",
            "  344  32  40  19  34  13  12  65  15  56]\n",
            " [ 30  32  19  20   0   0   0   1   0   1   1   0   0   1   0  32  27  34\n",
            "   28 353  34  38  40  16  21  49  14  17]\n",
            " [ 26  30  28  32   0   0   1   0   0   1   1   0   0   1   0  21  44  78\n",
            "   53  22 323  18  17  19  14  58  10  38]\n",
            " [ 40  13   8   7   0   0   0   0   0   0   0   0   0   0   0  18  19   9\n",
            "   14  29  15 565  10  23  32  26   6  13]\n",
            " [ 41  35  24  35   0   0   1   3   0   1   0   0   0   1   0  13  21  30\n",
            "   27  22  10  17 459  23  12  28  10  20]\n",
            " [ 11   3   1   2   0   0   0   0   0   1   0   0   0   0   0   2   5   2\n",
            "    3   5   4   5   9 763  10   1   9   9]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3   2   3\n",
            "    5   4   5  11   2   7 774   6   2   9]\n",
            " [  1   1   6   5   0   0   0   0   0   0   0   0   0   0   0  13  13  22\n",
            "   45  44  18  29  18   3   8 572   3  42]\n",
            " [  6   2   1   1   0   0   0   0   0   0   1   0   0   0   0   4   1   2\n",
            "    1   1   2   1   0   8   1   2 798   0]\n",
            " [  7   4   5   1   0   0   0   0   1   0   0   0   0   0   0   6  12  15\n",
            "   40   9  32  24  18  16  11  46   0 581]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.66      0.77      0.71       827\n",
            "           2       0.10      0.12      0.11       827\n",
            "           3       0.09      0.11      0.10       845\n",
            "           4       0.04      0.06      0.05       788\n",
            "           5       0.08      0.05      0.06        19\n",
            "           6       0.00      0.00      0.00        47\n",
            "           7       0.00      0.00      0.00        83\n",
            "           8       0.00      0.00      0.00       118\n",
            "           9       0.00      0.00      0.00       134\n",
            "          10       0.00      0.00      0.00       122\n",
            "          11       0.00      0.00      0.00        89\n",
            "          12       0.00      0.00      0.00        51\n",
            "          13       0.00      0.00      0.00        46\n",
            "          14       0.00      0.00      0.00        20\n",
            "          15       0.00      0.00      0.00        25\n",
            "          16       0.60      0.48      0.53       814\n",
            "          17       0.49      0.39      0.43       831\n",
            "          18       0.54      0.45      0.49       845\n",
            "          19       0.48      0.40      0.43       868\n",
            "          20       0.53      0.44      0.48       808\n",
            "          21       0.49      0.39      0.43       835\n",
            "          22       0.68      0.67      0.67       847\n",
            "          23       0.61      0.55      0.58       833\n",
            "          24       0.76      0.90      0.83       845\n",
            "          25       0.81      0.93      0.86       834\n",
            "          26       0.60      0.68      0.64       843\n",
            "          27       0.86      0.96      0.91       832\n",
            "          29       0.64      0.70      0.67       828\n",
            "\n",
            "    accuracy                           0.50     14904\n",
            "   macro avg       0.32      0.32      0.32     14904\n",
            "weighted avg       0.50      0.50      0.50     14904\n",
            "\n",
            "Accuracy: 0.5030193236714976\n",
            "\n",
            "--- Evaluation for k-Nearest Neighbors ---\n",
            "Confusion Matrix:\n",
            " [[521 152  29  18   0   0   0   0   0   2   0   0   0   0   0  13  10   5\n",
            "   12  11  11  13  19   7   0   0   3   1]\n",
            " [131 135 334 130   3   0   6   2   5   1   4   1   1   0   0  14  14   5\n",
            "    5  11   7   5  10   1   0   0   0   2]\n",
            " [ 54 475  47 146   5   2   3   4   6   3   2   0   0   0   0  13  13  11\n",
            "   15  14  11   1  16   1   0   2   1   0]\n",
            " [ 56 432 133  35   1   5   5   5   7   4   3   1   0   0   0  17  16   4\n",
            "    9  16  10   2  18   2   0   5   1   1]\n",
            " [  0   8   5   5   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  1  17  15  10   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   3   0   0   0   0   0]\n",
            " [  4  36  20  13   0   0   0   0   0   0   0   0   0   0   0   3   2   1\n",
            "    1   2   1   0   0   0   0   0   0   0]\n",
            " [  4  64  21  17   0   0   0   0   0   0   0   0   0   0   0   3   1   1\n",
            "    0   1   2   0   4   0   0   0   0   0]\n",
            " [  2  80  25  12   0   0   0   0   0   0   0   0   0   0   0   0   2   2\n",
            "    2   6   1   0   2   0   0   0   0   0]\n",
            " [  6  69  24  11   0   0   0   0   1   0   0   0   0   0   0   2   2   0\n",
            "    1   1   3   1   1   0   0   0   0   0]\n",
            " [  2  51  19   8   0   0   0   0   0   0   0   0   0   0   0   2   2   1\n",
            "    1   1   0   1   0   0   0   1   0   0]\n",
            " [  3  26  11   6   0   0   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    0   2   1   0   0   0   0   0   0   0]\n",
            " [  3  30   6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    1   1   2   0   2   0   0   0   0   0]\n",
            " [  0  14   2   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "    0   1   0   0   0   1   0   0   0   0]\n",
            " [  2  14   2   2   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0   1   2   0   0   0   0   0   0   0]\n",
            " [ 42 175  70  46   0   0   0   0   2   0   0   0   1   0   0 336  22  19\n",
            "   22  14  15  13   6  10   0   4   8   9]\n",
            " [ 32 171  83  33   0   0   1   1   4   5   0   4   0   0   0  18 304  31\n",
            "   31  21  35   8  10   2   4  15   4  14]\n",
            " [ 37 137  67  37   0   1   0   1   0   2   1   0   0   1   0  29  55 314\n",
            "    9  14  81   8  15  11   6  11   1   7]\n",
            " [ 39 197  95  33   0   0   1   1   3   4   4   0   1   1   2  19  31  20\n",
            "  292  19  24   7  13   4   1  29   2  26]\n",
            " [ 53 141  78  49   0   0   2   2   5   4   4   1   1   0   0  21  16  15\n",
            "   22 295  11  19  14   4   5  35   4   7]\n",
            " [ 31 155  69  48   0   0   0   2   7   2   3   4   1   1   0  17  43  77\n",
            "   31  13 253  12   9   7   3  24   2  21]\n",
            " [ 69 112  41  10   0   1   1   1   1   4   1   1   0   1   0  34  20  19\n",
            "   26  30  10 414   3  12  14  11   1  10]\n",
            " [ 75 117  76  57   0   0   2   3   5   3   3   2   1   1   0  15  20  22\n",
            "   13  22  10   5 345  11   0  17   1   7]\n",
            " [ 19  29   9   8   0   0   0   0   0   0   0   1   0   1   0  18  10   4\n",
            "    7   3   8   3  10 705   4   1   3   2]\n",
            " [  7  37  27   1   0   1   0   0   0   2   1   1   0   0   0  12   8   7\n",
            "    7  10  11  15   2   3 672   1   2   7]\n",
            " [  7  44  52  36   0   1   3   0   4   9   8   0   1   1   2  26  41  26\n",
            "   36  68  22  16  19   0   0 384   1  36]\n",
            " [  8  13   2   2   0   0   0   0   0   0   0   0   0   0   0   8   1   1\n",
            "    0   4   2   0   5   3   2   0 781   0]\n",
            " [ 13  30  24  18   0   0   1   1   2   2   4   0   1   0   0  27  16  19\n",
            "   53  12  36  20   8   7   5  66   0 463]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.43      0.63      0.51       827\n",
            "           2       0.05      0.16      0.07       827\n",
            "           3       0.03      0.06      0.04       845\n",
            "           4       0.04      0.04      0.04       788\n",
            "           5       0.10      0.05      0.07        19\n",
            "           6       0.00      0.00      0.00        47\n",
            "           7       0.00      0.00      0.00        83\n",
            "           8       0.00      0.00      0.00       118\n",
            "           9       0.00      0.00      0.00       134\n",
            "          10       0.00      0.00      0.00       122\n",
            "          11       0.00      0.00      0.00        89\n",
            "          12       0.00      0.00      0.00        51\n",
            "          13       0.00      0.00      0.00        46\n",
            "          14       0.00      0.00      0.00        20\n",
            "          15       0.00      0.00      0.00        25\n",
            "          16       0.52      0.41      0.46       814\n",
            "          17       0.47      0.37      0.41       831\n",
            "          18       0.52      0.37      0.43       845\n",
            "          19       0.49      0.34      0.40       868\n",
            "          20       0.50      0.37      0.42       808\n",
            "          21       0.44      0.30      0.36       835\n",
            "          22       0.74      0.49      0.59       847\n",
            "          23       0.65      0.41      0.50       833\n",
            "          24       0.89      0.83      0.86       845\n",
            "          25       0.94      0.81      0.87       834\n",
            "          26       0.63      0.46      0.53       843\n",
            "          27       0.96      0.94      0.95       832\n",
            "          29       0.76      0.56      0.64       828\n",
            "\n",
            "    accuracy                           0.42     14904\n",
            "   macro avg       0.33      0.27      0.29     14904\n",
            "weighted avg       0.51      0.42      0.45     14904\n",
            "\n",
            "Accuracy: 0.4225040257648953\n",
            "\n",
            "--- Evaluation for Multilayer Perceptron ---\n",
            "Confusion Matrix:\n",
            " [[657  41   3   4   0   0   0   0   0   0   0   0   0   0   0  10   8   9\n",
            "    3  10  16  12  16  13   1   1  18   5]\n",
            " [ 96 180 102 102   0   0   0   0   0   0   0   0   0   0   0  88  21  28\n",
            "   13  37  33  26  52  16   3   7  12  11]\n",
            " [ 49 101 205 123   0   0   0   0   0   0   0   0   0   0   0  67  12  28\n",
            "   13  45  32  35  69  20   6  12   7  21]\n",
            " [ 43  95  89 173   0   0   0   0   0   0   0   0   0   0   0  87  16  28\n",
            "   13  43  39  27  78  10   0  14  18  15]\n",
            " [  2   5   5   3   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
            "    0   0   0   0   2   0   0   0   0   0]\n",
            " [  4   8  11  11   0   0   0   0   0   0   0   0   0   0   0   4   1   0\n",
            "    1   0   0   1   6   0   0   0   0   0]\n",
            " [ 10  18  17  14   0   0   0   0   0   0   0   0   0   0   0   5   2   2\n",
            "    2   2   0   0  11   0   0   0   0   0]\n",
            " [  6  13  22  17   0   0   0   0   0   0   0   0   0   0   0  13   4   5\n",
            "    2   0   4   2  25   0   0   1   1   3]\n",
            " [  9  19  25  28   0   0   0   1   0   0   0   0   0   0   0   4   7   6\n",
            "    1   7   6   3  16   0   1   0   0   1]\n",
            " [  8  10  24  16   0   0   0   0   0   0   0   0   0   0   0   4   3   4\n",
            "    4  11  11   6  12   4   1   0   0   4]\n",
            " [  8   6  17   9   0   0   0   0   0   0   0   0   0   0   0   5   2   2\n",
            "    2  11   5   2  11   0   0   2   2   5]\n",
            " [  1   6   6   4   0   0   0   0   0   0   0   0   0   0   0   4   0   4\n",
            "    1   2   6   1   6   7   0   0   1   2]\n",
            " [  2   4   5   4   0   0   0   0   0   0   0   0   0   0   0   3   1   2\n",
            "    1   4   5   3   3   2   0   1   2   4]\n",
            " [  2   2   0   3   0   0   0   0   0   0   0   0   0   0   0   2   0   1\n",
            "    0   2   0   0   3   2   0   3   0   0]\n",
            " [  1   3   0   3   0   0   0   0   0   0   0   0   0   0   0   3   1   2\n",
            "    0   4   2   2   2   1   0   0   1   0]\n",
            " [ 53  19  52  36   0   0   0   0   0   0   0   0   0   0   0 266  15  38\n",
            "   27  49  35  59  49  39   7  18  19  33]\n",
            " [ 33  33  52  28   0   0   0   0   0   0   0   0   0   0   0  29 196  60\n",
            "   23  50  88  61  40  30  15  39   7  47]\n",
            " [ 38  33  43  29   0   0   0   0   0   0   0   0   0   0   0  44  40 210\n",
            "   30  43 115  52  38  26  14  45  15  30]\n",
            " [ 40  18  52   8   0   0   0   0   0   0   0   0   0   0   0  39  35  29\n",
            "  274  64  65  69  31  12   7  55  16  54]\n",
            " [ 36  21  31  31   0   0   0   0   0   0   0   0   0   0   0  35  22  22\n",
            "   31 284  75  80  37  16   8  55  12  12]\n",
            " [ 34  30  19  31   0   0   0   0   0   0   0   0   0   0   0  42  63  50\n",
            "   12  37 292  61  12  15  12  62  17  46]\n",
            " [ 30   8   6   2   0   0   0   0   0   0   0   0   0   0   0   5  12  25\n",
            "   21  23  21 579  10  24  24  27   5  25]\n",
            " [ 52  19  32  33   0   0   0   0   0   0   0   0   0   0   0  29  14  32\n",
            "   10  22  18  35 451  26   6  29   8  17]\n",
            " [ 13   5   5   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    1   4   4  10  11 769   8   2   8   3]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   3   1   0\n",
            "    1   1   6  14   1   6 786   1   2   9]\n",
            " [  3   1   7   6   0   0   0   0   0   0   0   0   0   0   0   3  10  18\n",
            "   25  37  30  28  20   1   4 601   1  48]\n",
            " [  4   0   0   1   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
            "    1   4   2   2   2   3   2   1 808   0]\n",
            " [  6   0   9   1   0   0   0   0   0   0   0   0   0   0   0   1   7   8\n",
            "   36  10  18  28  13  11   8  42   0 630]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.53      0.79      0.64       827\n",
            "           2       0.26      0.22      0.24       827\n",
            "           3       0.24      0.24      0.24       845\n",
            "           4       0.24      0.22      0.23       788\n",
            "           5       0.00      0.00      0.00        19\n",
            "           6       0.00      0.00      0.00        47\n",
            "           7       0.00      0.00      0.00        83\n",
            "           8       0.00      0.00      0.00       118\n",
            "           9       0.00      0.00      0.00       134\n",
            "          10       0.00      0.00      0.00       122\n",
            "          11       0.00      0.00      0.00        89\n",
            "          12       0.00      0.00      0.00        51\n",
            "          13       0.00      0.00      0.00        46\n",
            "          14       0.00      0.00      0.00        20\n",
            "          15       0.00      0.00      0.00        25\n",
            "          16       0.33      0.33      0.33       814\n",
            "          17       0.40      0.24      0.30       831\n",
            "          18       0.34      0.25      0.29       845\n",
            "          19       0.50      0.32      0.39       868\n",
            "          20       0.35      0.35      0.35       808\n",
            "          21       0.31      0.35      0.33       835\n",
            "          22       0.48      0.68      0.57       847\n",
            "          23       0.44      0.54      0.48       833\n",
            "          24       0.73      0.91      0.81       845\n",
            "          25       0.86      0.94      0.90       834\n",
            "          26       0.59      0.71      0.65       843\n",
            "          27       0.82      0.97      0.89       832\n",
            "          29       0.61      0.76      0.68       828\n",
            "\n",
            "    accuracy                           0.49     14904\n",
            "   macro avg       0.29      0.32      0.30     14904\n",
            "weighted avg       0.45      0.49      0.46     14904\n",
            "\n",
            "Accuracy: 0.49389425657541597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Táº¡o DataFrame tá»« dá»¯ liá»‡u Ä‘Ã£ cÃ¢n báº±ng\n",
        "df_balanced = pd.DataFrame(X_balanced, columns=df.columns[:-1])  # Láº¥y tÃªn cá»™t tá»« df gá»‘c\n",
        "df_balanced['Rings'] = y_balanced\n",
        "\n",
        "# LÆ°u DataFrame vÃ o file CSV\n",
        "df_balanced.to_csv('/content/drive/MyDrive/CFA-CFA_MC/abalone_balanced.csv', index=False)"
      ],
      "metadata": {
        "id": "z7QBmiWxhBrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'y_balanced' is your balanced target variable\n",
        "sns.countplot(x=y_balanced)\n",
        "plt.xlabel('Rings')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Rings After Balancing')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "iQg_Eg0Mk1uO",
        "outputId": "a8c0fc9b-12e1-48aa-9ee9-83087029dcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Encode categorical feature 'Sex'\n",
        "le = LabelEncoder()\n",
        "data['Sex'] = le.fit_transform(data['Sex'])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['Rings']).values\n",
        "y = data['Rings'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE for each class\n",
        "X_resampled = []\n",
        "y_resampled = []\n",
        "for class_label in np.unique(y_train):\n",
        "    # Create a binary target variable for the current class\n",
        "    y_binary = (y_train == class_label).astype(int)\n",
        "\n",
        "    # Determine k_neighbors based on available samples for the class\n",
        "    k = min(5, np.sum(y_binary) - 1)  # Ensure k_neighbors is less than the number of samples\n",
        "\n",
        "    # Apply SMOTE to oversample the minority class\n",
        "    # If there's only one sample for the class, SMOTE won't be applied\n",
        "    if np.sum(y_binary) > 1:\n",
        "        smote_temp = SMOTE(random_state=42, k_neighbors=k)  # Create a temporary SMOTE object with adjusted k\n",
        "        X_oversampled, y_oversampled = smote_temp.fit_resample(X_train, y_binary)\n",
        "\n",
        "        # Extract instances belonging to the current class from the oversampled data\n",
        "        indices = np.where(y_oversampled == 1)[0]\n",
        "        X_resampled.extend(X_oversampled[indices])\n",
        "        y_resampled.extend([class_label] * len(indices))\n",
        "    else:\n",
        "        # Handle the case where there's only one sample for the class\n",
        "        indices = np.where(y_binary == 1)[0]\n",
        "        X_resampled.extend(X_train[indices])\n",
        "        y_resampled.extend([class_label] * len(indices))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_resampled = np.array(X_resampled)\n",
        "y_resampled = np.array(y_resampled)\n",
        "\n",
        "# ----------------------------------\n",
        "# Train and evaluate classifiers\n",
        "# ----------------------------------\n",
        "\n",
        "# 1. Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_resampled, y_resampled)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# 2. k-Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_resampled, y_resampled)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# 3. Multilayer Perceptron Classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "mlp.fit(X_resampled, y_resampled)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# ----------------------------------\n",
        "# Print evaluation results\n",
        "# ----------------------------------\n",
        "\n",
        "def evaluate_classifier(y_test, y_pred, classifier_name):\n",
        "    print(f\"\\n--- Evaluation for {classifier_name} ---\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "evaluate_classifier(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_classifier(y_test, y_pred_knn, \"k-Nearest Neighbors\")\n",
        "evaluate_classifier(y_test, y_pred_mlp, \"Multilayer Perceptron\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAFSq7EFpOA1",
        "outputId": "cb2bd323-3ba0-44f0-91ae-34083fff1e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation for Random Forest ---\n",
            "Confusion Matrix:\n",
            " [[ 2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 6  2  4  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  4 17  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 14 13 12  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  4 16 23 19 10  4  3  2  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  1  3 17 34 21  5  3  5  1  1  4  1  0  1  1  0  0  0  0]\n",
            " [ 0  0  0  4  9 32 27 21 16 13  5  6  4  1  1  2  1  0  0  0  0]\n",
            " [ 0  0  0  3  6 11 22 21 22 13 13  5  4  4  4  2  5  2  2  0  0]\n",
            " [ 0  1  0  0  1  6 13 13 16 11 11  5  4  2  2  4  2  1  0  1  0]\n",
            " [ 0  0  0  1  1  3  4  7  8  5  4  5  3  3  1  4  1  0  1  0  0]\n",
            " [ 0  0  0  1  1  1  1  2  4  4  3  7  2  2  1  1  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  3  1  3  4  2  0  1  4  5  0  1  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  2  0  1  1  4  2  3  6  0  0  1  1  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  2  0  2  1  1  1  1  1  1  0  1  0  1]\n",
            " [ 0  0  0  0  0  0  1  1  1  1  2  1  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  1  0  2  2  2  1  0  0  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  1  2  0  0  0  2  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  1  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  1  0  1  0  1  0  0  0  0  0  0  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.15      0.67      0.25         3\n",
            "           4       0.15      0.15      0.15        13\n",
            "           5       0.42      0.53      0.47        32\n",
            "           6       0.28      0.27      0.27        48\n",
            "           7       0.32      0.27      0.29        84\n",
            "           8       0.29      0.34      0.32        99\n",
            "           9       0.26      0.19      0.22       142\n",
            "          10       0.26      0.15      0.19       139\n",
            "          11       0.19      0.17      0.18        93\n",
            "          12       0.08      0.10      0.09        51\n",
            "          13       0.06      0.10      0.07        31\n",
            "          14       0.03      0.04      0.03        26\n",
            "          15       0.09      0.14      0.11        21\n",
            "          16       0.04      0.08      0.05        13\n",
            "          17       0.07      0.12      0.09         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.11      0.25      0.15         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.20       836\n",
            "   macro avg       0.13      0.17      0.14       836\n",
            "weighted avg       0.22      0.20      0.21       836\n",
            "\n",
            "Accuracy: 0.20334928229665072\n",
            "\n",
            "--- Evaluation for k-Nearest Neighbors ---\n",
            "Confusion Matrix:\n",
            " [[ 1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  4  3  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 4 12  8  4  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1 12 11 19  3  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  3  6 23 14 16  9  3  3  4  1  1  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  1  9 15 22 22  5  5  8  0  5  3  2  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  5 10 23 33 18 18 13  2  6  6  2  1  3  1  0  1  0  0]\n",
            " [ 0  0  0  1 11 16 13 22 12 21 12  8  5  3  3  5  5  1  1  0  0]\n",
            " [ 0  0  0  0  1  7 14 11 13 16 10  3  6  4  3  2  2  1  0  0  0]\n",
            " [ 0  0  0  1  1  4  4  5  5  6  4  2  5  3  5  3  2  0  1  0  0]\n",
            " [ 0  0  0  2  1  1  2  3  2  4  2  6  1  4  0  1  0  1  1  0  0]\n",
            " [ 0  0  0  0  0  1  3  4  1  0  4  1  2  2  3  1  1  2  0  0  1]\n",
            " [ 0  0  0  0  0  1  0  1  1  1  3  4  2  5  0  1  0  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  2  0  1  0  0  2  2  4  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  2  0  0  1  2  0  1  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  1  2  0  2  1  1  0  0  2  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  1  1  0  0  1  1  0  0  1  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  1  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  1  0  0  0  1]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.10      0.33      0.15         3\n",
            "           4       0.17      0.31      0.22        13\n",
            "           5       0.27      0.25      0.26        32\n",
            "           6       0.20      0.23      0.21        48\n",
            "           7       0.18      0.17      0.17        84\n",
            "           8       0.23      0.22      0.23        99\n",
            "           9       0.32      0.23      0.27       142\n",
            "          10       0.28      0.16      0.20       139\n",
            "          11       0.20      0.14      0.16        93\n",
            "          12       0.08      0.12      0.09        51\n",
            "          13       0.05      0.06      0.06        31\n",
            "          14       0.03      0.04      0.03        26\n",
            "          15       0.06      0.10      0.07        21\n",
            "          16       0.06      0.15      0.09        13\n",
            "          17       0.05      0.12      0.07         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.10      0.25      0.14         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.50      0.25      0.33         4\n",
            "\n",
            "    accuracy                           0.17       836\n",
            "   macro avg       0.14      0.15      0.13       836\n",
            "weighted avg       0.21      0.17      0.18       836\n",
            "\n",
            "Accuracy: 0.1722488038277512\n",
            "\n",
            "--- Evaluation for Multilayer Perceptron ---\n",
            "Confusion Matrix:\n",
            " [[ 1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 6  6  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 4 14  7  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  4  9 22  8  2  1  0  1  0  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  1  6 27 23 17  5  1  0  3  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  1  1  6 19 36 14  2  5  6  1  1  2  0  1  3  0  0  0  0  1]\n",
            " [ 0  0  0  8 14 26 24 12 16 25  8  2  1  1  1  2  1  1  0  0  0]\n",
            " [ 0  0  0  1 13 13 20 11 18 18  9  4  9  7  3  5  2  3  3  0  0]\n",
            " [ 0  0  0  3  1  3 12  8 17 20  8  1  5  4  2  7  1  1  0  0  0]\n",
            " [ 0  0  0  1  2  2  2  1 10  7  2  1  4  3  4  4  3  2  1  0  2]\n",
            " [ 0  0  0  1  2  0  0  2  3  4  5  1  1  2  2  4  1  2  1  0  0]\n",
            " [ 0  0  0  0  0  1  0  1  2  3  6  0  2  0  1  3  3  1  2  0  1]\n",
            " [ 0  0  0  0  0  0  0  2  1  1  2  2  2  2  1  1  3  1  2  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  1  1  2  1  2  2  0  2  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  0  1  0  2  1  2  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  3  0  0  0  2  1  0  3  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  1  0  0  1  0  1  1  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  1  0  1  0  0  0  1  0  0  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.09      0.33      0.14         3\n",
            "           4       0.21      0.46      0.29        13\n",
            "           5       0.29      0.22      0.25        32\n",
            "           6       0.30      0.46      0.36        48\n",
            "           7       0.27      0.27      0.27        84\n",
            "           8       0.36      0.36      0.36        99\n",
            "           9       0.31      0.17      0.22       142\n",
            "          10       0.28      0.08      0.12       139\n",
            "          11       0.22      0.18      0.20        93\n",
            "          12       0.08      0.14      0.10        51\n",
            "          13       0.12      0.16      0.14        31\n",
            "          14       0.00      0.00      0.00        26\n",
            "          15       0.07      0.10      0.08        21\n",
            "          16       0.08      0.15      0.11        13\n",
            "          17       0.09      0.25      0.13         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.20       836\n",
            "   macro avg       0.13      0.16      0.13       836\n",
            "weighted avg       0.24      0.20      0.20       836\n",
            "\n",
            "Accuracy: 0.19736842105263158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load data (replace 'abalone.csv' with your data file)\n",
        "#data = pd.read_csv('abalone.csv')\n",
        "\n",
        "# Encode categorical feature 'Sex'\n",
        "le = LabelEncoder()\n",
        "data['Sex'] = le.fit_transform(data['Sex'])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['Rings']).values\n",
        "y = data['Rings'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply ADASYN for each class\n",
        "X_resampled = []\n",
        "y_resampled = []\n",
        "for class_label in np.unique(y_train):\n",
        "    # Create a binary target variable for the current class\n",
        "    y_binary = (y_train == class_label).astype(int)\n",
        "\n",
        "    # Determine n_neighbors based on available samples for the class\n",
        "    n_neighbors = min(5, np.sum(y_binary) - 1)  # Ensure n_neighbors is less than the number of samples\n",
        "\n",
        "    # Apply ADASYN to oversample the minority class\n",
        "    # If there's only one sample for the class, ADASYN won't be applied\n",
        "    if np.sum(y_binary) > 1:\n",
        "        adasyn_temp = ADASYN(random_state=42, n_neighbors=n_neighbors)  # Create a temporary ADASYN object\n",
        "        X_oversampled, y_oversampled = adasyn_temp.fit_resample(X_train, y_binary)\n",
        "\n",
        "        # Extract instances belonging to the current class from the oversampled data\n",
        "        indices = np.where(y_oversampled == 1)[0]\n",
        "        X_resampled.extend(X_oversampled[indices])\n",
        "        y_resampled.extend([class_label] * len(indices))\n",
        "    else:\n",
        "        # Handle the case where there's only one sample for the class\n",
        "        indices = np.where(y_binary == 1)[0]\n",
        "        X_resampled.extend(X_train[indices])\n",
        "        y_resampled.extend([class_label] * len(indices))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_resampled = np.array(X_resampled)\n",
        "y_resampled = np.array(y_resampled)\n",
        "\n",
        "# ----------------------------------\n",
        "# Train and evaluate classifiers\n",
        "# ----------------------------------\n",
        "\n",
        "# 1. Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_resampled, y_resampled)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# 2. k-Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_resampled, y_resampled)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# 3. Multilayer Perceptron Classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "mlp.fit(X_resampled, y_resampled)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# ----------------------------------\n",
        "# Print evaluation results\n",
        "# ----------------------------------\n",
        "\n",
        "def evaluate_classifier(y_test, y_pred, classifier_name):\n",
        "    print(f\"\\n--- Evaluation for {classifier_name} ---\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "evaluate_classifier(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_classifier(y_test, y_pred_knn, \"k-Nearest Neighbors\")\n",
        "evaluate_classifier(y_test, y_pred_mlp, \"Multilayer Perceptron\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUFnc1MobmS-",
        "outputId": "7547c879-9bb9-4bc6-adc5-0941c5d4fccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation for Random Forest ---\n",
            "Confusion Matrix:\n",
            " [[ 2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  4  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  6 13  7  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 12 14 11  5  3  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  5 15 28 20  8  2  2  1  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  1  4 18 33 18  8  6  6  1  1  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  4  6 28 28 23 22 12  5  5  5  0  2  2  0  0  0  0  0]\n",
            " [ 0  0  0  1  6 15 26 20 16 15  9  8  4  4  3  3  5  3  1  0  0]\n",
            " [ 0  0  1  0  2  6 13 12 17  8 12  8  4  1  4  3  1  0  0  1  0]\n",
            " [ 0  0  0  1  0  5  3  4  9  9  3  4  4  3  0  3  1  1  1  0  0]\n",
            " [ 0  0  0  1  2  1  1  3  1  5  3  4  3  2  1  1  0  2  1  0  0]\n",
            " [ 0  0  0  0  0  2  0  6  2  2  0  1  3  6  0  1  1  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  2  0  1  1  4  2  3  6  0  0  1  1  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  1  1  0  2  0  2  2  1  1  1  0  1  0  0]\n",
            " [ 0  0  0  0  0  0  1  1  1  1  2  1  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  2  0  2  2  1  1  0  0  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  2  0  1  0  2  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  1  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  1  1  1  0  0  0  0  0  0  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.17      0.67      0.27         3\n",
            "           4       0.25      0.31      0.28        13\n",
            "           5       0.37      0.41      0.39        32\n",
            "           6       0.29      0.29      0.29        48\n",
            "           7       0.38      0.33      0.35        84\n",
            "           8       0.29      0.33      0.31        99\n",
            "           9       0.27      0.20      0.23       142\n",
            "          10       0.24      0.14      0.18       139\n",
            "          11       0.21      0.18      0.20        93\n",
            "          12       0.14      0.18      0.16        51\n",
            "          13       0.07      0.10      0.08        31\n",
            "          14       0.03      0.04      0.03        26\n",
            "          15       0.09      0.14      0.11        21\n",
            "          16       0.07      0.15      0.10        13\n",
            "          17       0.07      0.12      0.09         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.21       836\n",
            "   macro avg       0.14      0.17      0.15       836\n",
            "weighted avg       0.23      0.21      0.22       836\n",
            "\n",
            "Accuracy: 0.21291866028708134\n",
            "\n",
            "--- Evaluation for k-Nearest Neighbors ---\n",
            "Confusion Matrix:\n",
            " [[ 1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 6  3  3  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 3 13  7  4  4  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2 11 10 18  4  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  5 23 21 19  6  1  3  1  1  1  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  1  1 10 16 23 16  8  4  8  1  4  3  3  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  7  7 23 28 18 18 17  4  8  3  2  1  4  1  0  1  0  0]\n",
            " [ 0  0  0  2  8 18 16 18 16 17 11  6  4  5  4  5  7  1  1  0  0]\n",
            " [ 0  0  0  0  1  8 11 17 12 10  9  5  6  7  3  2  1  1  0  0  0]\n",
            " [ 0  0  0  1  0  4  4  4  6  7  3  2  4  4  5  4  2  0  1  0  0]\n",
            " [ 0  0  0  1  2  1  3  4  1  5  1  5  1  3  0  3  0  0  1  0  0]\n",
            " [ 0  0  0  0  0  2  1  4  2  0  2  2  2  2  3  2  1  2  0  0  1]\n",
            " [ 0  0  0  0  0  0  1  1  2  1  2  2  2  4  1  0  1  3  1  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  2  0  1  0  0  2  2  4  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  3  0  2  1  0  0  1  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  1  2  0  1  2  1  0  1  2  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  2  0  0  0  1  0  0  1  1  0  1]\n",
            " [ 0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  1  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  1  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  1  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  1  0  0  0  1]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.10      0.33      0.15         3\n",
            "           4       0.13      0.23      0.17        13\n",
            "           5       0.26      0.22      0.24        32\n",
            "           6       0.17      0.21      0.19        48\n",
            "           7       0.27      0.25      0.26        84\n",
            "           8       0.23      0.23      0.23        99\n",
            "           9       0.31      0.20      0.24       142\n",
            "          10       0.23      0.13      0.17       139\n",
            "          11       0.17      0.13      0.15        93\n",
            "          12       0.10      0.14      0.11        51\n",
            "          13       0.03      0.03      0.03        31\n",
            "          14       0.05      0.08      0.06        26\n",
            "          15       0.07      0.10      0.08        21\n",
            "          16       0.06      0.15      0.08        13\n",
            "          17       0.05      0.12      0.07         8\n",
            "          18       0.04      0.08      0.05        12\n",
            "          19       0.00      0.00      0.00         7\n",
            "          20       0.10      0.25      0.14         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.33      0.25      0.29         4\n",
            "\n",
            "    accuracy                           0.17       836\n",
            "   macro avg       0.13      0.15      0.13       836\n",
            "weighted avg       0.20      0.17      0.18       836\n",
            "\n",
            "Accuracy: 0.1686602870813397\n",
            "\n",
            "--- Evaluation for Multilayer Perceptron ---\n",
            "Confusion Matrix:\n",
            " [[ 2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 9  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5 15  7  2  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  5 16 14  4  6  0  0  1  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
            " [ 0  2 12 20 19 19  8  1  0  0  1  1  0  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  2  0  5 17 37 20  3  2  7  0  1  1  0  1  2  0  0  0  0  1  0]\n",
            " [ 0  0  0  5 11 29 36 11  9 21  5  5  3  1  1  2  1  1  1  0  0  0]\n",
            " [ 0  0  0  2  9 14 28 13 10 20  7  7  6  5  2  7  2  3  4  0  0  0]\n",
            " [ 0  0  0  2  2  3 17 14  9 15  7  2  7  3  1  7  1  1  0  1  1  0]\n",
            " [ 0  0  0  1  1  2  5  3  5  9  2  1  7  3  3  3  2  0  2  0  2  0]\n",
            " [ 0  0  0  1  1  2  0  3  1  4  3  3  0  4  2  2  2  2  1  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  2  1  3  3  2  0  1  2  3  4  1  2  0  1  0]\n",
            " [ 0  0  0  0  0  0  2  1  0  1  1  2  2  2  0  0  4  1  3  0  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  2  2  1  2  2  0  2  0  1  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  1  0  0  1  2  1  1  0  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  1  2  1  0  1  3  0  0  2  2  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2  0  0  1  0  0  0  1  1  1  0  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.12      0.67      0.21         3\n",
            "           4       0.11      0.23      0.15        13\n",
            "           5       0.19      0.22      0.21        32\n",
            "           6       0.27      0.29      0.28        48\n",
            "           7       0.28      0.23      0.25        84\n",
            "           8       0.33      0.37      0.35        99\n",
            "           9       0.31      0.25      0.28       142\n",
            "          10       0.25      0.09      0.14       139\n",
            "          11       0.22      0.10      0.13        93\n",
            "          12       0.11      0.18      0.14        51\n",
            "          13       0.10      0.10      0.10        31\n",
            "          14       0.07      0.08      0.07        26\n",
            "          15       0.06      0.10      0.08        21\n",
            "          16       0.07      0.15      0.10        13\n",
            "          17       0.12      0.25      0.17         8\n",
            "          18       0.00      0.00      0.00        12\n",
            "          19       0.04      0.14      0.06         7\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         3\n",
            "          23       0.00      0.00      0.00         4\n",
            "          24       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.19       836\n",
            "   macro avg       0.12      0.16      0.12       836\n",
            "weighted avg       0.23      0.19      0.20       836\n",
            "\n",
            "Accuracy: 0.19258373205741627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}