{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b36fc2",
   "metadata": {},
   "source": [
    "# Reproduction of Experiments on Dataset D22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84a8a2",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840be18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.insert(0, os.path.join(\"..\", \"src\"))\n",
    "import pandas as pd\n",
    "\n",
    "path = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "df = pd.read_csv(path, sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0537cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"quality\"\n",
    "\n",
    "majority_labels = [5]\n",
    "minority_labels = [3, 9]\n",
    "\n",
    "df_filtered = df[df[label_column].isin(majority_labels + minority_labels)].copy()\n",
    "\n",
    "df_filtered.loc[df_filtered[label_column].isin(majority_labels), label_column] = 1\n",
    "df_filtered.loc[df_filtered[label_column].isin(minority_labels), label_column] = 0\n",
    "\n",
    "X = df_filtered.drop(label_column, axis=1)\n",
    "y = df_filtered[label_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b0edd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1457\n",
       "0      25\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2496ab18",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa38529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted pipeline and custom transformer to support modifying both X and y (only on training data)\n",
    "# adapted from: https://stackoverflow.com/questions/25539311/custom-transformer-for-sklearn-pipeline-that-alters-both-x-and-y\n",
    "#from sklearn import pipeline\n",
    "#from sklearn.base import clone\n",
    "#from sklearn.utils import _print_elapsed_time\n",
    "#from sklearn.utils.validation import check_memory\n",
    "#from sklearn.pipeline import _fit_transform_one\n",
    "\n",
    "#class Pipeline(pipeline.Pipeline):\n",
    "#\n",
    "#    def _fit(self, X, y=None, **fit_params_steps):\n",
    "#        # shallow copy of steps - this should really be steps_\n",
    "#        self.steps = list(self.steps)\n",
    "#        self._validate_steps()\n",
    "#        # Setup the memory\n",
    "#        memory = check_memory(self.memory)\n",
    "#\n",
    "#        fit_transform_one_cached = memory.cache(_fit_transform_one)\n",
    "#\n",
    "#        for step_idx, name, transformer in self._iter(\n",
    "#            with_final=False, filter_passthrough=False\n",
    "#        ):\n",
    "#            if transformer is None or transformer == \"passthrough\":\n",
    "#                with _print_elapsed_time(\"Pipeline\", self._log_message(step_idx)):\n",
    "#                    continue\n",
    "#\n",
    "#            if hasattr(memory, \"location\") and memory.location is None:\n",
    "#                # we do not clone when caching is disabled to\n",
    "#                # preserve backward compatibility\n",
    "#                cloned_transformer = transformer\n",
    "#            else:\n",
    "#                cloned_transformer = clone(transformer)\n",
    "#            # Fit or load from cache the current transformer\n",
    "#            X, fitted_transformer = fit_transform_one_cached(\n",
    "#                cloned_transformer,\n",
    "#                X,\n",
    "#                y,\n",
    "#                None,\n",
    "#                message_clsname=\"Pipeline\",\n",
    "#                message=self._log_message(step_idx),\n",
    "#                **fit_params_steps[name],\n",
    "#            )\n",
    "#            \n",
    "#            if isinstance(X, tuple):    ###### unpack X if is tuple X = (X,y)\n",
    "#                X, y = X\n",
    "#            \n",
    "#            # Replace the transformer of the step with the fitted\n",
    "#            # transformer. This is necessary when loading the transformer\n",
    "#            # from the cache.\n",
    "#            self.steps[step_idx] = (name, fitted_transformer)\n",
    "#        return X, y\n",
    "#    \n",
    "#    def fit(self, X, y=None, **fit_params):\n",
    "#        \"\"\"Fit the model.\n",
    "#        Fit all the transformers one after the other and transform the\n",
    "#        data. Finally, fit the transformed data using the final estimator.\n",
    "#        Parameters\n",
    "#        ----------\n",
    "#        X : iterable\n",
    "#            Training data. Must fulfill input requirements of first step of the\n",
    "#            pipeline.\n",
    "#        y : iterable, default=None\n",
    "#            Training targets. Must fulfill label requirements for all steps of\n",
    "#            the pipeline.\n",
    "#        **fit_params : dict of string -> object\n",
    "#            Parameters passed to the ``fit`` method of each step, where\n",
    "#            each parameter name is prefixed such that parameter ``p`` for step\n",
    "#            ``s`` has key ``s__p``.\n",
    "#        Returns\n",
    "#        -------\n",
    "#        self : object\n",
    "#            Pipeline with fitted steps.\n",
    "#        \"\"\"\n",
    "#        fit_params_steps = self._check_fit_params(**fit_params)\n",
    "#        Xt = self._fit(X, y, **fit_params_steps)\n",
    "#        \n",
    "#        if isinstance(Xt, tuple):    ###### unpack X if is tuple X = (X,y)\n",
    "#            Xt, y = Xt \n",
    "#        \n",
    "#        with _print_elapsed_time(\"Pipeline\", self._log_message(len(self.steps) - 1)):\n",
    "#            if self._final_estimator != \"passthrough\":\n",
    "#                fit_params_last_step = fit_params_steps[self.steps[-1][0]]\n",
    "#                self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
    "#\n",
    "#        return self\n",
    "    \n",
    "#class TrainDataAugmenter():\n",
    "#    \"\"\"Transformer that only applies augmentation to training data, not to test data\"\"\"\n",
    "#    def __init__(self, augmentation_func, *arguments_for_augmentation_func):\n",
    "#        self.augmentation_func = augmentation_func\n",
    "#        self.arguments_for_augmentation_func = arguments_for_augmentation_func\n",
    "#        \n",
    "#    def fit(self, X, y=None):\n",
    "#        print(\"Calling fit\")\n",
    "#        return self\n",
    "#\n",
    "#    def transform(self, X, y=None):\n",
    "#        \"\"\"This function is called on test data\"\"\"\n",
    "#        print(\"Calling transform\")\n",
    "#        return X\n",
    "#    \n",
    "#    def fit_transform(self, X, y=None):\n",
    "#        \"\"\"This function is called on training data\"\"\"\n",
    "#        print(\"Calling fit_transform\")\n",
    "#        X_augmented, y_augmented = self.augmentation_func(X, y, *self.arguments_for_augmentation_func)\n",
    "#        return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f224a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c142d6c",
   "metadata": {},
   "source": [
    "> **Note:** In the following, we use a custom piece of code for the grid search and cross-validation. We do this to enforce that the augmentation/oversampling step is only applied to training data and the test data is actually kept separate. For the baseline model, this means that we could also simply make use of the functions provided by sklearn instead of our custom code. However, in order to make the results comparable, we use the same code in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034c2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=7018321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e60aa7",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b6218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c0eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 400, 600],\n",
    "    'max_depth': [None, 4, 6, 10, 20, 30, 50, 80, 100],\n",
    "}\n",
    "\n",
    "# compute all combinations of parameters\n",
    "combination_dicts = list(ParameterGrid(rf_param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa5529",
   "metadata": {},
   "source": [
    "### Baseline (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a681a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    #print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = RandomForestClassifier(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train, y_train)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a121e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'n_estimators': 200}\n",
      "Best AUC: 0.8323561402985022\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63180e",
   "metadata": {},
   "source": [
    "To verify that our code works as expected, we can compare to a regular sklearn grid search here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd90cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398663089017558"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_search = GridSearchCV(RandomForestClassifier(random_state=19231823), rf_param_grid, scoring=\"roc_auc\")\n",
    "baseline_search.fit(X, y)\n",
    "baseline_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2c118",
   "metadata": {},
   "source": [
    "We can see that the best model found by a sklearn grid search performs similarly well to our best model, which indicates that the code works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7ee99",
   "metadata": {},
   "source": [
    "### With CFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5fead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfa import Iterative_CFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3012ce",
   "metadata": {},
   "source": [
    "For CFA, we try two different approaches, since it is not entirely clear from the paper what the authors actually did.\n",
    "1. The first approach strictly follows the pseudo-code and description given in section 3.2 of the paper. \n",
    "2. In an earlier section of the paper, the authors say that _\"the class of [a] new [synthetic counterfactual] instance needs to be verified by the underlying ML model.\"_ This means that we use some ML model trained on the data (without CFA) to assign a class to a new synthetic counterfactual, and only keep those that were classified to be a minority instance. This seems to lead to much more reasonable synthetic counterfactuals (see visualizations of the algorithm in exp001) but, at the same time, often means that the algorithm is unable to produce a fully balanced dataset (since it may terminate early).\n",
    "\n",
    "> **Note:** We also use a different tolerance level of 50% here, since the 10%-threshold proposed by the authors does not yield any \"good\" native counterfactuals, which makes the algorithm unusable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14e8eb",
   "metadata": {},
   "source": [
    "#### Approach 1: No verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce379b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 19\n",
      "Number of 'good' native counterfactuals in data: 7\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1166, Minority (label 0): 1166\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 1166\n",
      "Fold 1:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 23\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1162, Minority (label 0): 1162\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 1162\n",
      "Fold 2:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 3\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "Fold 3:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 22\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1164, Minority (label 0): 1164\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 1164\n",
      "Fold 4:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 10\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_augmented, y_train_augmented = Iterative_CFA(X_train, \n",
    "                                                         y_train, \n",
    "                                                         stddev_percent=50, \n",
    "                                                         verify_with_baseline_model=False,\n",
    "                                                         visualize_with_pca=False)\n",
    "    \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = RandomForestClassifier(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_augmented, y_train_augmented)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487e0673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 10, 'n_estimators': 400}\n",
      "Best AUC: 0.717917378820314\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f7b20",
   "metadata": {},
   "source": [
    "#### Approach 2: Verification of new synthetic counterfactuals with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759c0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 19\n",
      "Number of 'good' native counterfactuals in data: 7\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 19\n",
      "Fold 1:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 23\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 23\n",
      "Fold 2:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 3\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Fold 3:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 22\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 22\n",
      "Fold 4:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 10\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"Fitting baseline model needed for verification... \")\n",
    "    baseline_search = GridSearchCV(RandomForestClassifier(random_state=19231823), rf_param_grid, scoring=\"roc_auc\")\n",
    "    baseline_search.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_augmented, y_train_augmented = Iterative_CFA(X_train, \n",
    "                                                         y_train, \n",
    "                                                         stddev_percent=50, \n",
    "                                                         verify_with_baseline_model=True, \n",
    "                                                         baseline_model=baseline_search,\n",
    "                                                         visualize_with_pca=False)\n",
    "    \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = RandomForestClassifier(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_augmented, y_train_augmented)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9320dada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'n_estimators': 200}\n",
      "Best AUC: 0.8323561402985022\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144366c",
   "metadata": {},
   "source": [
    "### ADASYN instead of CFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "069cc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "ada = ADASYN(random_state=9317231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d398fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    #print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    X_train_resampled, y_train_resampled = ada.fit_resample(X_train, y_train)\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = RandomForestClassifier(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380485af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 20, 'n_estimators': 400}\n",
      "Best AUC: 0.7789910523678737\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2537f",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac56d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=52012318)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc282a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    #print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = RandomForestClassifier(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "315120fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'n_estimators': 600}\n",
      "Best AUC: 0.7998980148267136\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24e4e9",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef33eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\AppData\\Local\\Temp\\ipykernel_452\\1504384812.py:6: DeprecationWarning: Please use `LineSearchWarning` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import LineSearchWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5355c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\"max_iter\": [100, 200, 1000], \n",
    "                 \"C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                 \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\"]}\n",
    "\n",
    "# compute all combinations of parameters\n",
    "combination_dicts = list(ParameterGrid(lr_param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcd0ef",
   "metadata": {},
   "source": [
    "### Baseline (no augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    #print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = LogisticRegression(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train, y_train)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea382aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 100, 'max_iter': 100, 'solver': 'newton-cg'}\n",
      "Best AUC: 0.7668206151189778\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f1370",
   "metadata": {},
   "source": [
    "Again, we can compare to an out-of-the-box grid search to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad844b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\fredd\\Anaconda3\\envs\\cfa\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7660349291531328"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_search = GridSearchCV(LogisticRegression(random_state=19231823), lr_param_grid, scoring=\"roc_auc\")\n",
    "baseline_search.fit(X, y)\n",
    "baseline_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cdc1d",
   "metadata": {},
   "source": [
    "### With CFA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282abc2c",
   "metadata": {},
   "source": [
    "#### Approach 1: No verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "922959ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 19\n",
      "Number of 'good' native counterfactuals in data: 7\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1166, Minority (label 0): 1166\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 1166\n",
      "Fold 1:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 23\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1162, Minority (label 0): 1162\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 1162\n",
      "Fold 2:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 3\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "Fold 3:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 22\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1164, Minority (label 0): 1164\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 1164\n",
      "Fold 4:\n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 10\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 1168\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_augmented, y_train_augmented = Iterative_CFA(X_train, \n",
    "                                                         y_train, \n",
    "                                                         stddev_percent=50, \n",
    "                                                         verify_with_baseline_model=False, \n",
    "                                                         visualize_with_pca=False)\n",
    "\n",
    "    for param_comb in combination_dicts:\n",
    "        clf = LogisticRegression(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_augmented, y_train_augmented)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbcf11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'max_iter': 200, 'solver': 'lbfgs'}\n",
      "Best AUC: 0.7230129091143179\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b4e50",
   "metadata": {},
   "source": [
    "#### Approach 2: Verification of new synthetic counterfactuals with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebbb1655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 19\n",
      "Number of 'good' native counterfactuals in data: 7\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1166, Minority (label 0): 26\n",
      "Number of 'good' native counterfactuals in data: 13\n",
      "Data distribution after iteration 1:\n",
      "\tMajority (1): 1166, Minority (label 0): 30\n",
      "Number of 'good' native counterfactuals in data: 17\n",
      "Data distribution after iteration 2:\n",
      "\tMajority (1): 1166, Minority (label 0): 32\n",
      "Number of 'good' native counterfactuals in data: 19\n",
      "Data distribution after iteration 3:\n",
      "\tMajority (1): 1166, Minority (label 0): 34\n",
      "Number of 'good' native counterfactuals in data: 21\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1166, Minority (label 0): 34\n",
      "Fold 1:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 23\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1162, Minority (label 0): 25\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1162, Minority (label 0): 25\n",
      "Fold 2:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 3\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 20\n",
      "Number of 'good' native counterfactuals in data: 3\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 20\n",
      "Fold 3:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 22\n",
      "Number of 'good' native counterfactuals in data: 9\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1164, Minority (label 0): 23\n",
      "Number of 'good' native counterfactuals in data: 8\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1164, Minority (label 0): 23\n",
      "Fold 4:\n",
      "Fitting baseline model needed for verification... \n",
      "Data distribution before CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 18\n",
      "Number of 'good' native counterfactuals in data: 10\n",
      "Data distribution after iteration 0:\n",
      "\tMajority (1): 1168, Minority (label 0): 29\n",
      "Number of 'good' native counterfactuals in data: 16\n",
      "Classifier predicted all new synthetic counterfactuals to be in the majority class! => No new minority instances => Terminating...\n",
      "====================================================================\n",
      "Data distribution after CFA:\n",
      "\tMajority (1): 1168, Minority (label 0): 29\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"Fitting baseline model needed for verification... \")\n",
    "    baseline_search = GridSearchCV(LogisticRegression(random_state=19231823), lr_param_grid, scoring=\"roc_auc\")\n",
    "    baseline_search.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_augmented, y_train_augmented = Iterative_CFA(X_train, \n",
    "                                                         y_train, \n",
    "                                                         stddev_percent=50, \n",
    "                                                         verify_with_baseline_model=True, \n",
    "                                                         baseline_model=baseline_search,\n",
    "                                                         visualize_with_pca=False)\n",
    "\n",
    "    for param_comb in combination_dicts:\n",
    "        clf = LogisticRegression(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_augmented, y_train_augmented)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7849b98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1000, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Best AUC: 0.7630778556650009\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620f44a",
   "metadata": {},
   "source": [
    "### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    X_train_resampled, y_train_resampled = ada.fit_resample(X_train, y_train)\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = LogisticRegression(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2b992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 1, 'max_iter': 200, 'solver': 'lbfgs'}\n",
      "Best AUC: 0.7471711051514929\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5832d",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04fa857",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    scores_for_fold = []\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "    for param_comb in combination_dicts:\n",
    "        clf = LogisticRegression(random_state=19231823, **param_comb)\n",
    "        clf.fit(X_train_resampled, y_train_resampled)\n",
    "        current_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        #print(f\"Score for combination {param_comb}: {current_score}\")\n",
    "        scores_for_fold.append(current_score)\n",
    "        \n",
    "    all_scores.append(scores_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3e2611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'max_iter': 200, 'solver': 'lbfgs'}\n",
      "Best AUC: 0.7633598537002654\n"
     ]
    }
   ],
   "source": [
    "score_avg_over_folds = np.array(all_scores).mean(axis=0)\n",
    "best_score_idx = score_avg_over_folds.argmax()\n",
    "print(f\"Best params: {combination_dicts[best_score_idx]}\")\n",
    "print(f\"Best AUC: {score_avg_over_folds[best_score_idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfa",
   "language": "python",
   "name": "cfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
